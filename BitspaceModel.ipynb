{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1nV6OQvzsplCwFPWufEmm_z1a_h1sQ7I_",
      "authorship_tag": "ABX9TyOi+xz2DrCDx6cvGj0N0mOP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NIKHILCHAUHAN87667/ML_GenerativeAI_projects/blob/main/BitspaceModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO4D7AwsQHf7",
        "outputId": "dbe26923-c557-4697-fed4-2a23c5aaeeb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trimesh\n",
            "  Downloading trimesh-4.9.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.12/dist-packages (from trimesh) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading trimesh-4.9.0-py3-none-any.whl (736 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m736.5/736.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trimesh\n",
            "Successfully installed trimesh-4.9.0\n"
          ]
        }
      ],
      "source": [
        "# Run this first in Colab\n",
        "!pip install trimesh tqdm torch torchvision scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports & config\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import trimesh\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import traceback\n",
        "\n",
        "# CONFIG - edit paths below\n",
        "INPUT_DIR = \"/content/drive/MyDrive/dataset\"   # <- put your models here\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/bitspace_voxels\"  # <- where voxel outputs go\n",
        "VOXEL_RES = 32   # start with 32^3\n",
        "SAVE_NPY = True  # save individual .npy files\n",
        "COMBINED_SAVE_PATH = os.path.join(OUTPUT_DIR, \"bitspace_voxels.pt\")\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(\"loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rSgqqE9RVQL",
        "outputId": "20f13195-0b1d-4a03-8199-a00a52df2ff2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "def normalize_mesh(mesh):\n",
        "    \"\"\"Center + uniformly scale mesh to unit extents.\"\"\"\n",
        "    if mesh is None or mesh.is_empty:\n",
        "        return None\n",
        "    try:\n",
        "        mesh.remove_unreferenced_vertices()\n",
        "    except Exception:\n",
        "        pass\n",
        "    ext = mesh.extents\n",
        "    max_e = float(ext.max())\n",
        "    if max_e <= 0 or np.isnan(max_e):\n",
        "        return None\n",
        "    # center\n",
        "    try:\n",
        "        mesh.apply_translation(-mesh.centroid)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # scale to fit into a cube of side 1.0\n",
        "    try:\n",
        "        mesh.apply_scale(1.0 / max_e)\n",
        "    except Exception:\n",
        "        return None\n",
        "    return mesh\n",
        "\n",
        "def mesh_to_voxel_matrix(mesh, res=32):\n",
        "    \"\"\"Voxelize to exactly (res,res,res) binary grid (uint8).\"\"\"\n",
        "    try:\n",
        "        # choose pitch assuming mesh extents ~1.0 after normalization\n",
        "        pitch = mesh.extents.max() / max(1, (res - 1))\n",
        "        v = mesh.voxelized(pitch=pitch)\n",
        "        mat = v.matrix.astype(np.uint8)\n",
        "        sx, sy, sz = mat.shape\n",
        "        out = np.zeros((res,res,res), dtype=np.uint8)\n",
        "        ox = (res - sx) // 2\n",
        "        oy = (res - sy) // 2\n",
        "        oz = (res - sz) // 2\n",
        "        ex = min(sx, res - ox)\n",
        "        ey = min(sy, res - oy)\n",
        "        ez = min(sz, res - oz)\n",
        "        out[ox:ox+ex, oy:oy+ey, oz:oz+ez] = mat[:ex, :ey, :ez]\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        # fallback: sample points on surface and rasterize them\n",
        "        try:\n",
        "            pts = mesh.sample(20000)\n",
        "            pts = (pts - pts.min(axis=0))\n",
        "            if pts.max() > 0:\n",
        "                pts = pts / pts.max() * (res - 1)\n",
        "            idx = np.floor(pts).astype(int)\n",
        "            idx = np.clip(idx, 0, res-1)\n",
        "            out = np.zeros((res,res,res), dtype=np.uint8)\n",
        "            out[idx[:,0], idx[:,1], idx[:,2]] = 1\n",
        "            return out\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "def try_load_mesh(path):\n",
        "    \"\"\"Robust mesh loader using trimesh. Returns a single merged mesh or None.\"\"\"\n",
        "    try:\n",
        "        m = trimesh.load(path, force='mesh')\n",
        "        if isinstance(m, trimesh.Scene):\n",
        "            # combine scene geometry into a single mesh\n",
        "            try:\n",
        "                meshes = [g for g in m.geometry.values()]\n",
        "                if len(meshes) == 0:\n",
        "                    return None\n",
        "                m = trimesh.util.concatenate(meshes)\n",
        "            except Exception:\n",
        "                # fallback: attempt dump\n",
        "                m = trimesh.util.concatenate(m.dump()) if hasattr(m, 'dump') else None\n",
        "        return m\n",
        "    except Exception:\n",
        "        try:\n",
        "            return trimesh.load_mesh(path)\n",
        "        except Exception:\n",
        "            return None\n"
      ],
      "metadata": {
        "id": "kvpsGpOtRg7G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class VoxelUNetAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim=256):\n",
        "        super(VoxelUNetAutoencoder, self).__init__()\n",
        "\n",
        "        # --- Encoder ---\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv3d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv3d(32, 64, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.enc3 = nn.Sequential(\n",
        "            nn.Conv3d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm3d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.enc4 = nn.Sequential(\n",
        "            nn.Conv3d(128, 256, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm3d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Bottleneck fully-connected compression\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4 * 4, latent_dim)\n",
        "        self.fc2 = nn.Linear(latent_dim, 256 * 4 * 4 * 4)\n",
        "\n",
        "        # --- Decoder (with skip connections) ---\n",
        "        self.up1 = nn.ConvTranspose3d(256, 128, 2, stride=2)\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.Conv3d(128 + 128, 128, 3, padding=1),\n",
        "            nn.BatchNorm3d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.up2 = nn.ConvTranspose3d(128, 64, 2, stride=2)\n",
        "        self.dec2 = nn.Sequential(\n",
        "            nn.Conv3d(64 + 64, 64, 3, padding=1),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.up3 = nn.ConvTranspose3d(64, 32, 2, stride=2)\n",
        "        self.dec3 = nn.Sequential(\n",
        "            nn.Conv3d(32 + 32, 32, 3, padding=1),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Output\n",
        "        self.final = nn.Conv3d(32, 1, 1)\n",
        "        self.out_act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encode\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(e1)\n",
        "        e3 = self.enc3(e2)\n",
        "        e4 = self.enc4(e3)\n",
        "\n",
        "        # Latent\n",
        "        b = e4.view(e4.size(0), -1)\n",
        "        latent = self.fc1(b)\n",
        "        b = self.fc2(latent)\n",
        "        b = b.view(e4.size())\n",
        "\n",
        "        # Decode with skip connections\n",
        "        d1 = self.up1(b)\n",
        "        d1 = torch.cat([d1, e3], dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        d2 = self.up2(d1)\n",
        "        d2 = torch.cat([d2, e2], dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        d3 = self.up3(d2)\n",
        "        d3 = torch.cat([d3, e1], dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "\n",
        "        out = self.final(d3)\n",
        "        out = self.out_act(out)\n",
        "\n",
        "        return out, latent\n"
      ],
      "metadata": {
        "id": "N6r-JDGbUg0B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "class VoxelDataset(Dataset):\n",
        "    def __init__(self, directory):\n",
        "        self.files = list(Path(directory).rglob(\"*.pt\"))\n",
        "        random.shuffle(self.files)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = torch.load(self.files[idx])\n",
        "        voxel = data[\"voxel\"].float()\n",
        "\n",
        "        # ✅ Normalize tensor shape\n",
        "        # Sometimes augmentation causes wrong ordering like (1,32,1,32,32)\n",
        "        voxel = voxel.squeeze()  # remove any extra 1-dimensions\n",
        "        shape = voxel.shape\n",
        "\n",
        "        # Fix any misaligned dimensions\n",
        "        if len(shape) != 3:\n",
        "            voxel = voxel.view(32, 32, 32)\n",
        "\n",
        "        voxel = voxel.unsqueeze(0)  # make it (1, D, D, D)\n",
        "        return voxel\n",
        "orig_dir = \"/content/drive/MyDrive/bitspace_voxels\"\n",
        "aug_dir = \"/content/drive/MyDrive/bitspace_voxels_augmented\"\n",
        "\n",
        "dataset = VoxelDataset(orig_dir) + VoxelDataset(aug_dir)\n",
        "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n"
      ],
      "metadata": {
        "id": "_Cyk2IqgUzzD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = VoxelUNetAutoencoder(latent_dim=512).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 95\n",
        "lambda_bce = 0.1  # weight for BCE in the hybrid loss\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for vox in train_loader:\n",
        "        vox = vox.to(device)\n",
        "        recon, latent = model(vox)\n",
        "\n",
        "        # --- Hybrid loss ---\n",
        "        mse_loss = F.mse_loss(recon, vox)\n",
        "        bce_loss = F.binary_cross_entropy(recon, vox)\n",
        "        loss = mse_loss + lambda_bce * bce_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{EPOCHS}]  Loss: {avg_loss:.6f}\")\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/bitspace_voxel_autoencoder_hybrid.pth\")\n",
        "print(\"✅ Training complete with hybrid loss! Model saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TEZ7a22U5Bz",
        "outputId": "eadeddf0-dfe1-4a71-cddc-8f02ad55d3e3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch [1/95]  Loss: 0.149942\n",
            "Epoch [2/95]  Loss: 0.065025\n",
            "Epoch [3/95]  Loss: 0.035251\n",
            "Epoch [4/95]  Loss: 0.021480\n",
            "Epoch [5/95]  Loss: 0.014470\n",
            "Epoch [6/95]  Loss: 0.010480\n",
            "Epoch [7/95]  Loss: 0.008003\n",
            "Epoch [8/95]  Loss: 0.006363\n",
            "Epoch [9/95]  Loss: 0.005225\n",
            "Epoch [10/95]  Loss: 0.004356\n",
            "Epoch [11/95]  Loss: 0.003707\n",
            "Epoch [12/95]  Loss: 0.003198\n",
            "Epoch [13/95]  Loss: 0.002793\n",
            "Epoch [14/95]  Loss: 0.002470\n",
            "Epoch [15/95]  Loss: 0.002194\n",
            "Epoch [16/95]  Loss: 0.001967\n",
            "Epoch [17/95]  Loss: 0.001771\n",
            "Epoch [18/95]  Loss: 0.001608\n",
            "Epoch [19/95]  Loss: 0.001466\n",
            "Epoch [20/95]  Loss: 0.001336\n",
            "Epoch [21/95]  Loss: 0.001227\n",
            "Epoch [22/95]  Loss: 0.001130\n",
            "Epoch [23/95]  Loss: 0.001049\n",
            "Epoch [24/95]  Loss: 0.000970\n",
            "Epoch [25/95]  Loss: 0.000901\n",
            "Epoch [26/95]  Loss: 0.000839\n",
            "Epoch [27/95]  Loss: 0.000785\n",
            "Epoch [28/95]  Loss: 0.000733\n",
            "Epoch [29/95]  Loss: 0.000687\n",
            "Epoch [30/95]  Loss: 0.000646\n",
            "Epoch [31/95]  Loss: 0.000608\n",
            "Epoch [32/95]  Loss: 0.000573\n",
            "Epoch [33/95]  Loss: 0.000540\n",
            "Epoch [34/95]  Loss: 0.000509\n",
            "Epoch [35/95]  Loss: 0.000480\n",
            "Epoch [36/95]  Loss: 0.000454\n",
            "Epoch [37/95]  Loss: 0.000428\n",
            "Epoch [38/95]  Loss: 0.000409\n",
            "Epoch [39/95]  Loss: 0.000383\n",
            "Epoch [40/95]  Loss: 0.000363\n",
            "Epoch [41/95]  Loss: 0.000346\n",
            "Epoch [42/95]  Loss: 0.000331\n",
            "Epoch [43/95]  Loss: 0.000312\n",
            "Epoch [44/95]  Loss: 0.000298\n",
            "Epoch [45/95]  Loss: 0.000283\n",
            "Epoch [46/95]  Loss: 0.000272\n",
            "Epoch [47/95]  Loss: 0.000259\n",
            "Epoch [48/95]  Loss: 0.000248\n",
            "Epoch [49/95]  Loss: 0.000236\n",
            "Epoch [50/95]  Loss: 0.000225\n",
            "Epoch [51/95]  Loss: 0.000216\n",
            "Epoch [52/95]  Loss: 0.000208\n",
            "Epoch [53/95]  Loss: 0.000199\n",
            "Epoch [54/95]  Loss: 0.000191\n",
            "Epoch [55/95]  Loss: 0.000183\n",
            "Epoch [56/95]  Loss: 0.000175\n",
            "Epoch [57/95]  Loss: 0.000168\n",
            "Epoch [58/95]  Loss: 0.000163\n",
            "Epoch [59/95]  Loss: 0.000155\n",
            "Epoch [60/95]  Loss: 0.000150\n",
            "Epoch [61/95]  Loss: 0.000144\n",
            "Epoch [62/95]  Loss: 0.000139\n",
            "Epoch [63/95]  Loss: 0.000134\n",
            "Epoch [64/95]  Loss: 0.000130\n",
            "Epoch [65/95]  Loss: 0.000124\n",
            "Epoch [66/95]  Loss: 0.000119\n",
            "Epoch [67/95]  Loss: 0.000115\n",
            "Epoch [68/95]  Loss: 0.000111\n",
            "Epoch [69/95]  Loss: 0.000107\n",
            "Epoch [70/95]  Loss: 0.000104\n",
            "Epoch [71/95]  Loss: 0.000101\n",
            "Epoch [72/95]  Loss: 0.000097\n",
            "Epoch [73/95]  Loss: 0.000093\n",
            "Epoch [74/95]  Loss: 0.000090\n",
            "Epoch [75/95]  Loss: 0.000087\n",
            "Epoch [76/95]  Loss: 0.000084\n",
            "Epoch [77/95]  Loss: 0.000080\n",
            "Epoch [78/95]  Loss: 0.000077\n",
            "Epoch [79/95]  Loss: 0.000074\n",
            "Epoch [80/95]  Loss: 0.000071\n",
            "Epoch [81/95]  Loss: 0.000070\n",
            "Epoch [82/95]  Loss: 0.000067\n",
            "Epoch [83/95]  Loss: 0.000065\n",
            "Epoch [84/95]  Loss: 0.000063\n",
            "Epoch [85/95]  Loss: 0.000061\n",
            "Epoch [86/95]  Loss: 0.000059\n",
            "Epoch [87/95]  Loss: 0.000057\n",
            "Epoch [88/95]  Loss: 0.000055\n",
            "Epoch [89/95]  Loss: 0.000053\n",
            "Epoch [90/95]  Loss: 0.000052\n",
            "Epoch [91/95]  Loss: 0.000050\n",
            "Epoch [92/95]  Loss: 0.000048\n",
            "Epoch [93/95]  Loss: 0.000047\n",
            "Epoch [94/95]  Loss: 0.000046\n",
            "Epoch [95/95]  Loss: 0.000044\n",
            "✅ Training complete with hybrid loss! Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load model + one voxel sample\n",
        "model.eval()\n",
        "sample = next(iter(train_loader))[0].unsqueeze(0).to(device)\n",
        "recon, latent = model(sample)\n",
        "\n",
        "# Convert to numpy for visualization\n",
        "orig_np = sample[0, 0].detach().cpu().numpy()\n",
        "recon_np = recon[0, 0].detach().cpu().numpy()\n",
        "\n",
        "# Visualize mid-slices\n",
        "fig, axs = plt.subplots(1, 2, figsize=(8,4))\n",
        "axs[0].imshow(orig_np[16], cmap='gray')\n",
        "axs[0].set_title(\"Original Slice\")\n",
        "axs[1].imshow(recon_np[16], cmap='gray')\n",
        "axs[1].set_title(\"Reconstructed Slice\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Latent vector size: {latent.numel()} vs Original: {orig_np.size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "6aGMlYrxW_hG",
        "outputId": "adb904b2-0ff6-4daa-c1ac-4bded78d7aa8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latent vector size: 512 vs Original: 32768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"/content/drive/MyDrive/bitspace_autoencoder_full.pth\")\n",
        "print(\"✅ Full model (with architecture) saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ck9eOmvYuzz",
        "outputId": "5c78339b-13fe-463e-efe9-e4022d3840d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Full model (with architecture) saved!\n"
          ]
        }
      ]
    }
  ]
}